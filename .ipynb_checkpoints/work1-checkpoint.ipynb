{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DwONxxODq041"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b721ddfdf76b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mConcatenate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLSTM\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrelu\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCategoricalCrossentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "import cv2\n",
    "import gc\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "from tensorflow.keras.layers import Input,Dense,Dropout,Embedding,Concatenate,Flatten,LSTM ,Bidirectional,GRU\n",
    "from tensorflow.keras.activations import relu ,sigmoid,softmax\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.optimizers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jiuBa-iar7uf"
   },
   "outputs": [],
   "source": [
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value) # Python\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    tf.random.set_seed(seed_value+1000)\n",
    "    #os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    #os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    #os.environ['TF_KERAS'] = '1'\n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_all(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjNTVr_m6hxY"
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5wkGJ7EP6kkN"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "  n_folds=10\n",
    "  random_state=42\n",
    "  tbs = 1024\n",
    "  vbs = 512\n",
    "  data_path=\"data\"\n",
    "  result_path=\"results\"\n",
    "  models_path=\"models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nP_iHJ_R3Kc5"
   },
   "source": [
    "# plot and util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-EzHOux13P7y"
   },
   "outputs": [],
   "source": [
    "def write_to_txt(file_name,column):\n",
    "    with open(file_name, 'w') as f:\n",
    "        for item in column:\n",
    "            f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHPxRJ600cHa"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "SDaW_vDn0mZw"
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(os.path.join(Config.data_path,\"train.csv\"))\n",
    "test=pd.read_csv(os.path.join(Config.data_path,\"test.csv\"))\n",
    "aae=pd.read_csv(os.path.join(Config.data_path,\"amino_acid_embeddings.csv\"))\n",
    "submission=pd.read_csv(os.path.join(Config.data_path,\"SampleSubmission.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jkLdhtMa3i9X"
   },
   "outputs": [],
   "source": [
    "train[\"Sequence_len\"]=train[\"Sequence\"].apply(lambda x : len(x))\n",
    "test[\"Sequence_len\"]=test[\"Sequence\"].apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-bjNTTVW38HJ"
   },
   "outputs": [],
   "source": [
    "max_seq_length = 550 # max seq length in this data set is 550 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "igY0IaVA6S-0"
   },
   "outputs": [],
   "source": [
    "#stratified k fold\n",
    "train[\"folds\"]=-1\n",
    "kf = StratifiedKFold(n_splits=Config.n_folds, random_state=Config.random_state, shuffle=True)\n",
    "for fold, (_, val_index) in enumerate(kf.split(train,train[\"target\"])):\n",
    "        train.loc[val_index, \"folds\"] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "U2941IR05R6i",
    "outputId": "b406689a-0457-4952-a271-405bba5e1c94"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>target</th>\n",
       "      <th>Sequence_len</th>\n",
       "      <th>folds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_train_0</td>\n",
       "      <td>MVDGVMILPVLVMIAFPFPSMEDEKPKVNPKLYMCVCEGLSCGDEA...</td>\n",
       "      <td>0</td>\n",
       "      <td>509</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_train_1</td>\n",
       "      <td>MAQKENAYPWPYGSKTSQSGLNTLSQRVLRKEPATTSALALVNRFN...</td>\n",
       "      <td>1</td>\n",
       "      <td>345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_train_2</td>\n",
       "      <td>MRLWPRSLFGRLVLILVSGMLAAQILTSSIWYDVRHSQVLEIPTRL...</td>\n",
       "      <td>2</td>\n",
       "      <td>462</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_train_3</td>\n",
       "      <td>MNSIVKIMKMKQITYKLFMTTSLILLSFAVLIYLTLYFFLPTFYEQ...</td>\n",
       "      <td>2</td>\n",
       "      <td>490</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_train_4</td>\n",
       "      <td>MKLIYQNVLSFLLIIVTTISIIGYSEIGYARNQAYTQNYQRMESYA...</td>\n",
       "      <td>2</td>\n",
       "      <td>484</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                           Sequence  target  \\\n",
       "0  ID_train_0  MVDGVMILPVLVMIAFPFPSMEDEKPKVNPKLYMCVCEGLSCGDEA...       0   \n",
       "1  ID_train_1  MAQKENAYPWPYGSKTSQSGLNTLSQRVLRKEPATTSALALVNRFN...       1   \n",
       "2  ID_train_2  MRLWPRSLFGRLVLILVSGMLAAQILTSSIWYDVRHSQVLEIPTRL...       2   \n",
       "3  ID_train_3  MNSIVKIMKMKQITYKLFMTTSLILLSFAVLIYLTLYFFLPTFYEQ...       2   \n",
       "4  ID_train_4  MKLIYQNVLSFLLIIVTTISIIGYSEIGYARNQAYTQNYQRMESYA...       2   \n",
       "\n",
       "   Sequence_len  folds  \n",
       "0           509      9  \n",
       "1           345      1  \n",
       "2           462      9  \n",
       "3           490      6  \n",
       "4           484      2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "E91XIFBt5ely"
   },
   "outputs": [],
   "source": [
    "# reduce seq length\n",
    "if max_seq_length>550 : \n",
    "    train[\"Sequence\"] = train[\"Sequence\"].apply(lambda x: \"\".join(list(x)[0:max_seq_length]))\n",
    "    test[\"Sequence\"] = test[\"Sequence\"].apply(lambda x: \"\".join(list(x)[0:max_seq_length]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "wp9Vxk-96F2x"
   },
   "outputs": [],
   "source": [
    "voc_set = set(['P', 'V', 'I', 'K', 'N', 'B', 'F', 'Y', 'E', 'W', 'R', 'D', 'X', 'S', 'C', 'U', 'Q', 'A', 'M', 'H', 'L', 'G', 'T'])\n",
    "voc_set_map = { k:v for k , v in zip(voc_set,range(1,len(voc_set)+1))}\n",
    "number_of_class = train[\"target\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0PH9PeWrUDUp"
   },
   "outputs": [],
   "source": [
    "def encode(text_tensor, label):\n",
    "    encoded_text = [ voc_set_map[e] for e in list(text_tensor.numpy().decode())]\n",
    "    return encoded_text, label\n",
    "def encode_map_fn(text, label):\n",
    "    # py_func doesn't set the shape of the returned tensors.\n",
    "    encoded_text, label = tf.py_function(encode, \n",
    "                                       inp=[text, label], \n",
    "                                       Tout=(tf.int64, tf.int64))\n",
    "    encoded_text.set_shape([None])\n",
    "    label=tf.one_hot(label,number_of_class)\n",
    "    label.set_shape([number_of_class])\n",
    "    \n",
    "    return encoded_text, label\n",
    "def get_data_loader(file,batch_size,labels):\n",
    "    \n",
    "    label_data=tf.data.Dataset.from_tensor_slices(labels)\n",
    "    data_set=tf.data.TextLineDataset(file)\n",
    "    data_set=tf.data.Dataset.zip((data_set,label_data))\n",
    "\n",
    "    data_set=data_set.repeat()\n",
    "    data_set = data_set.shuffle(len(labels))\n",
    "    data_set=data_set.map(encode_map_fn,tf.data.experimental.AUTOTUNE)\n",
    "    data_set=data_set.padded_batch(batch_size)\n",
    "    data_set = data_set.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return data_set\n",
    "\n",
    "\n",
    "def get_data_loader_test(file,batch_size,labels):\n",
    "    \n",
    "    label_data=tf.data.Dataset.from_tensor_slices(labels.target)\n",
    "    data_set=tf.data.TextLineDataset(file)\n",
    "    data_set=tf.data.Dataset.zip((data_set,label_data))\n",
    "    data_set=data_set.map(encode_map_fn,tf.data.experimental.AUTOTUNE)\n",
    "    data_set=data_set.padded_batch(batch_size)\n",
    "    data_set = data_set.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQB3Nj9HA3mV"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "tad3YJYHA4oF"
   },
   "outputs": [],
   "source": [
    "def model():\n",
    "    name = \"seq\"\n",
    "    dropout_rate = 0.1\n",
    "    learning_rate = 0.001\n",
    "    sequnce = Input([None],name=\"sequnce\")\n",
    "    \n",
    "    EMB_layer = Embedding(input_dim = len(voc_set)+1, output_dim = 64, name = \"emb_layer\")\n",
    "    \n",
    "    GRU_layer_2 = GRU(units=256, name = \"gru_2\", return_sequences = False)\n",
    "    BIDIR_layer_2 = Bidirectional(GRU_layer_2, name=\"bidirectional_2\")\n",
    "    \n",
    "    Dens_layer_1 = Dense(units=512, activation=relu, kernel_regularizer=None, bias_regularizer=None, name=name+\"_dense_layer_1\")\n",
    "    Dens_layer_2 = Dense(units=256, activation=relu, kernel_regularizer=None, bias_regularizer=None, name=name+\"_dense_layer_2\")\n",
    "    \n",
    "    output = Dense(units=number_of_class, activation=softmax, kernel_regularizer=None, bias_regularizer=None, name=name+\"_dense_layer_output\")\n",
    "    \n",
    "    dropout_1 = Dropout(dropout_rate)\n",
    "    \n",
    "    \n",
    "    emb_layer = EMB_layer(sequnce)\n",
    "    logits = output(Dens_layer_2(dropout_1(Dens_layer_1(BIDIR_layer_2(emb_layer)))))\n",
    "\n",
    "    \n",
    "    model = tf.keras.Model(inputs={\"sequnce\":sequnce, },outputs=logits) \n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    #loss= tfa.losses.SigmoidFocalCrossEntropy(reduction=tf.keras.losses.Reduction.AUTO)\n",
    "    loss=CategoricalCrossentropy()\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[tf.keras.metrics.CategoricalAccuracy(name=\"Acc\")]) \n",
    "    model.summary()\n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8jCMXcwAyb9"
   },
   "source": [
    "# training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDJQCjRG_7hf"
   },
   "outputs": [],
   "source": [
    "def trainn(fold):\n",
    "    model_path=f\"model_{fold}.h5\"\n",
    "    df_train = train[train[\"folds\"] != fold].reset_index(drop=True)\n",
    "    df_valid = train[train[\"folds\"] == fold].reset_index(drop=True)\n",
    "    write_to_txt(f\"data/train_{fold}.txt\",df_train.Sequence)\n",
    "    write_to_txt(f\"data/valid_{fold}.txt\",df_valid.Sequence)\n",
    "    train_label=df_train[\"target\"]\n",
    "    valid_label=df_valid[\"target\"]\n",
    "    train_dl = get_data_loader(f\"data/train_{fold}.txt\",Config.tbs,train_label)\n",
    "    valid_dl = get_data_loader(f\"data/valid_{fold}.txt\",Config.vbs,valid_label)\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(Config.models_path,model_path),\n",
    "                                                 save_weights_only=True,monitor = 'val_loss',\n",
    "                                                 save_best_only=True,mode=\"min\", verbose=1)\n",
    "    callbacks=[checkpoint]\n",
    "    my_model = model()\n",
    "    \n",
    "    history = my_model.fit(train_dl,\n",
    "                    validation_data=valid_dl,\n",
    "                    epochs=15,\n",
    "                    verbose=1,\n",
    "                    batch_size=Config.tbs,\n",
    "                    validation_batch_size=Config.vbs,\n",
    "                    validation_steps=len(df_valid)//Config.vbs,\n",
    "                    steps_per_epoch=len(df_train)/Config.tbs,\n",
    "                    callbacks=callbacks\n",
    "                   )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSL8XDAnKMEt"
   },
   "outputs": [],
   "source": [
    "def predict(fold):\n",
    "  model_path=f\"model_{fold}.h5\"\n",
    "  write_to_txt(f\"data/test_{fold}.txt\",test.Sequence)\n",
    "  test[\"target\"]=0\n",
    "  test_label=test[\"target\"]\n",
    "  test_dl = get_data_loader_test(f\"data/test_{fold}.txt\",Config.vbs,test)\n",
    "  my_model = model()\n",
    "  my_model.load_weights(os.path.join(Config.models_path,model_path))\n",
    "  prediction=my_model.predict(test_dl)\n",
    "  return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "9A_lyejSCyaN",
    "outputId": "67490e03-2edf-447f-c919-7236ba90bde3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequnce (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "emb_layer (Embedding)        (None, None, 128)         3072      \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 512)               592896    \n",
      "_________________________________________________________________\n",
      "seq_dense_layer_1 (Dense)    (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "seq_dense_layer_2 (Dense)    (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "seq_dense_layer_output (Dens (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 992,008\n",
      "Trainable params: 992,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "176/399 [============>.................] - ETA: 3:52 - loss: 0.0079 - Acc: 0.9976"
     ]
    }
   ],
   "source": [
    "trainn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "SFWTYg1GCzM5",
    "outputId": "b5c1fcb7-266a-48bd-8a2e-f06450778936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequnce (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "emb_layer (Embedding)        (None, None, 128)         3072      \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 512)               592896    \n",
      "_________________________________________________________________\n",
      "seq_dense_layer_1 (Dense)    (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "seq_dense_layer_2 (Dense)    (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "seq_dense_layer_output (Dens (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 992,008\n",
      "Trainable params: 992,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "p=predict(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "A7hdOB_CSjUc"
   },
   "outputs": [],
   "source": [
    "sub=test[[\"ID\"]].copy()\n",
    "for i in range(number_of_class):\n",
    "    sub[\"target_{}\".format(i)]=p[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xpDAQN1ngIKV",
    "outputId": "813d9c6a-c304-489d-8c85-2b5825d6e7cb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_test_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_test_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_test_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_test_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_test_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID\n",
       "0  ID_test_0\n",
       "1  ID_test_1\n",
       "2  ID_test_2\n",
       "3  ID_test_3\n",
       "4  ID_test_4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Es4sMRDrgLGC"
   },
   "outputs": [],
   "source": [
    "sub.to_csv(os.path.join(Config.result_path,\"sub_p1_epoch15.csv\"),index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "work6.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
